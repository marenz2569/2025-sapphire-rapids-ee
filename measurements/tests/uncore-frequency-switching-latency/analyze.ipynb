{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from experiment_utils import Experiment, ExperimentFilter, Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = Experiment.get_experiments()\n",
    "experiments = list(filter(ExperimentFilter.by_experiment_name('uncore-frequency-switching-latency'), experiments))\n",
    "experiment = ExperimentFilter.get_latest(experiments)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FREQUENCY = \"Source Frequency [MHz]\"\n",
    "TARGET_FREQUENCY = \"Target Frequency [MHz]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns for log a dict of dict of dicts:\n",
    "# resulting_dict[source-frequency][target-frequency][metric]\n",
    "# metric can be \"t_gap\": the gap time during the switch of frequencies\n",
    "#               \"t_init\": how long it took to initialize the frequency switch\n",
    "#               \"source_p\": the performance of the workload before the assumed frequency switch\n",
    "#               \"target_p\": the performance of the workload after the assumed frequency switch\n",
    "# the latter metrics can be used to check for sanity\n",
    "# returns the pair of (all data, data with 1%, 50% and 99% quantile)\n",
    "def read_log_file(filename):\n",
    "\n",
    "    first_phase_regex='^(\\d+) MHz->(\\d+)Mhz Cycles per access before:(\\d+) after:(\\d+), switch after (\\d+) cycles, took (\\d+) cycles, switch timestamp before (\\d+), after (\\d+)$'\n",
    "\n",
    "    prog_1=re.compile(first_phase_regex)\n",
    "\n",
    "    f=open(filename)\n",
    "    data = []\n",
    "    for line in f:\n",
    "        result=re.match(prog_1, line)\n",
    "        if not result:\n",
    "            continue\n",
    "\n",
    "        source=int(result.group(1))\n",
    "        target=int(result.group(2))\n",
    "        source_p=int(result.group(3))\n",
    "        target_p=int(result.group(4))\n",
    "        t_init=float(result.group(5))/2E3\n",
    "        t_gap=float(result.group(6))/2E3\n",
    "        time_before=int(result.group(7))\n",
    "        time_after=int(result.group(8))\n",
    "\n",
    "        data.append({\n",
    "            SOURCE_FREQUENCY: source,\n",
    "            TARGET_FREQUENCY: target,\n",
    "            't_init': t_init,\n",
    "            't_gap': t_gap,\n",
    "            'source_p': source_p,\n",
    "            'target_p': target_p,\n",
    "            'time_before': time_before,\n",
    "            'time_after': time_after\n",
    "        })\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    data_all = pd.DataFrame(data)\n",
    "\n",
    "    data_all['wait_latency_before'] = data_all[\"time_before\"].diff() / 2E3\n",
    "    data_all['wait_latency_after'] = data_all[\"time_after\"].diff() / 2E3\n",
    "\n",
    "    data_all['nb_of_accesses_before_gap'] = data_all['t_init'] * 2E3 / data_all['source_p']\n",
    "\n",
    "    # Filter out invalid values where the source_p or target_p is zero\n",
    "    data_all = data_all[data_all['source_p'] != 0]\n",
    "    data_all = data_all[data_all['target_p'] != 0]\n",
    "\n",
    "    # discard the first row\n",
    "    data_all = data_all.iloc[1:]\n",
    "\n",
    "    data_quantile = pd.DataFrame()\n",
    "\n",
    "    for source in data_all[SOURCE_FREQUENCY].unique():\n",
    "        for target in data_all[TARGET_FREQUENCY].unique():\n",
    "            data = data_all[data_all[SOURCE_FREQUENCY] == source]\n",
    "            data = data[data[TARGET_FREQUENCY] == target]\n",
    "            data_quantile = pd.concat([data_quantile, pd.DataFrame([\n",
    "                {'median_t_init': np.median(data['t_init'].quantile(0.5)),\n",
    "                '1percentQuantile_t_init': data['t_init'].quantile(0.01),\n",
    "                '95percentQuantile_t_init': data['t_init'].quantile(0.95),\n",
    "                '99percentQuantile_t_init': data['t_init'].quantile(0.99),\n",
    "                'median_t_gap': np.median(data['t_gap'].quantile(0.5)),\n",
    "                '1percentQuantile_t_gap': data['t_gap'].quantile(0.01),\n",
    "                '95percentQuantile_t_gap': data['t_gap'].quantile(0.95),\n",
    "                '99percentQuantile_t_gap': data['t_gap'].quantile(0.99),\n",
    "                SOURCE_FREQUENCY: source,\n",
    "                TARGET_FREQUENCY: target}\n",
    "            ])], ignore_index=True)\n",
    "\n",
    "    return data_all, data_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(data,metric,metric_long,vmin,vmax,plt_filename):\n",
    "    plt.rcParams['figure.figsize'] = 5,5\n",
    "\n",
    "    ax = sns.heatmap(data=data.pivot(index=SOURCE_FREQUENCY, columns=TARGET_FREQUENCY, values=metric),\n",
    "                     vmin=vmin, vmax=vmax, square=True, cmap=\"viridis\", linecolor=\"black\", linewidths=0.5,\n",
    "                     cbar_kws={'label': metric_long})\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    Plotting.savefig(experiment, plt_filename, annotations_y_offset=0.025, annotations_y_spacing=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all, data_quantile = read_log_file(f'{experiment.path}/manual.2000.out')\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set of all performance values\n",
    "# The detection threshold has to be higher than all performance values in cycles\n",
    "all_performances = set(data_all['source_p'].tolist()).union(set(data_all['target_p']))\n",
    "print(f\"Lowest performance in cycles is {max(all_performances)}\")\n",
    "print(f\"Highest performance in cycles is {min(all_performances)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(data_quantile, \"1percentQuantile_t_init\", \"1% percentile of $t_{init}$ [µs]\", 0, 1000, \"1percentile-t-init.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(data_quantile, \"median_t_init\", \"Median of $t_{init}$ [µs]\", 0, 1000, \"median-t-init.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(data_quantile, \"95percentQuantile_t_init\", \"95% quantile of $t_{init}$ [µs]\", 0, 1000, \"95percentile-t-init.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(data_quantile, \"95percentQuantile_t_gap\", \"95% quantile of $t_{gap}$ [µs]\", 0, 10, \"95percentile-t-gap.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, height=5, xlim=(0, 250), ylim=(0, 250), col_wrap=4)\n",
    "    g.map(sns.scatterplot, 'source_p', 'target_p', alpha=0.3)\n",
    "    g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, height=5, xlim=(0, 1000), ylim=(0, 10), col_wrap=4)\n",
    "    g.map(sns.scatterplot, 't_init', 't_gap', alpha=0.3)\n",
    "    g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, height=5, xlim=(0, 10), col_wrap=4)\n",
    "    g.map(sns.ecdfplot, 't_gap')\n",
    "    g.add_legend()\n",
    "    for axi in g.axes:\n",
    "        axi.axvline(x=4, color='black', dashes=[2], linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, height=5, xlim=(0, 1000), col_wrap=4)\n",
    "    g.map(sns.ecdfplot, 't_init')\n",
    "    g.add_legend()\n",
    "    for axi in g.axes:\n",
    "        axi.axvline(x=575, color='black', dashes=[2], linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, xlim=(0, 10000), height=5, col_wrap=4)\n",
    "    g.map(sns.scatterplot, 'wait_latency_before', 't_init', alpha=0.3)\n",
    "    g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, xlim=(0, 10000), height=5, col_wrap=4)\n",
    "    g.map(sns.scatterplot, 'wait_latency_after', 't_init', alpha=0.3)\n",
    "    g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_freq in data_all[SOURCE_FREQUENCY].unique():\n",
    "    filtered_data = data_all\n",
    "    filtered_data = filtered_data[filtered_data[SOURCE_FREQUENCY] == source_freq]\n",
    "\n",
    "    g = sns.FacetGrid(filtered_data, col=TARGET_FREQUENCY, height=5, col_wrap=4)\n",
    "    g.map(sns.ecdfplot, 'nb_of_accesses_before_gap')\n",
    "    g.add_legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
